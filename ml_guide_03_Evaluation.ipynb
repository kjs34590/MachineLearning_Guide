{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 03 : 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝의 프로세스 : 데이터 가공/변환 -> 모델 학습/예측 -> **평가(Evaluation)**\n",
    "\n",
    "> **성능 평가 지표**\n",
    ">\n",
    "> 회귀 모델 : 실제값과 예측값의 오차 평균값에 기반 (ex : 오차에 절댓값을 씌운 뒤 평균 오차를 구하거나 오차의 제곱 값에 루트를 씌운 뒤 평균 오차를 구하는 방법 등 기본적으로 예측 오차를 가지고 정규화 수준을 재가공하는 방법)\n",
    ">\n",
    "> 분류 모델 : 기본적으로는 실제값과 예측값의 오류가 적은지의 정확도에 기반하지만, 그밖에도 다양한 지표 고려 필요\n",
    "> - 정확도(Accuracy)\n",
    "> - 오차행렬(Confusion Matrix)\n",
    "> - 정밀도(Precision)\n",
    "> - 재현율(Recall)\n",
    "> - F1 스코어\n",
    "> - ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 정확도 (Accuracy)\n",
    "\n",
    "$정확도(Accuracy) = \\cfrac{예측결과가 동일한 데이터 건수}{전체 예측 데이터 건수}$\n",
    "\n",
    "**정확도 지표의 문제점 확인하기**\n",
    "- 사이킷런의 BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별에 따라 생존자를 예측하는 Classifier 생성하기\n",
    "- (BaseEstimator : Customized 형태의 Estimator를 개발자가 생성할 수 있다.)\n",
    "- fit() 메서드는 아무것도 수행하지 않으며, 예측을 수행하는 predict()는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 0으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else : \n",
    "                pred[i] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 타이타닉 예측을 위한 전처리 함수 정의\n",
    "# Null 처리 함수\n",
    "def fillna(df) :\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "#데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 : 0.7877\n",
      "해석 : 단순한 알고리즘으로 예측해도 정확도는 높을 수 있다. 따라서 정확도만을 평가 지표로 사용하는 것은 신중해야 한다.\n"
     ]
    }
   ],
   "source": [
    "# MyDummyClassifier를 이용해 타이타닉 생존자 예측 수행\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                 test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는 : {0:.4f}'.format(accuracy_score(y_test, mypredictions)))\n",
    "print('해석 : 단순한 알고리즘으로 예측해도 정확도는 높을 수 있다. 따라서 정확도만을 평가 지표로 사용하는 것은 신중해야 한다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST 데이터셋을 활용해 정확도 지표 적용의 문제점 확인하기**\n",
    "- MNIST 데이터셋은 원래 0부터 9까지의 숫자 이미지 픽셀 정보를 기반으로, 레이블 값이 0부터 9까지 있는 멀티 레이블 분류를 위한 것이나, 여기서는 레이블 값이 7인 것만 True, 나머지는 False로 변환해 이진 분류 문제로 변형해 확인하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터셋의 크기만큼 모두 0값으로 만들어 변환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "# 사이킷런 내장 데이터셋인 load_digits()를 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7이 아니면 False이고 0으로 변환\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 데이터 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 단순히 0으로 했을 때 정확도는 : 0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 데이터 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 단순히 0으로 했을 때 정확도는 : {:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 오차행렬 (Confusion Matrix)\n",
    "\n",
    "- 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고(confused) 있는지 보여주는 지표\n",
    "- 이진 분류의 예측 오류에 대해 파악할 수 있는 지표\n",
    "\n",
    "> TN : 예측값을 Negative 값 0으로 예측, 실제 값 역시 Negative 값 0\n",
    ">\n",
    "> FP : 예측값을 Positive 값 1로 예측, 실제 값은 Negative 값 0\n",
    ">\n",
    "> FN : 예측값을 Negative 값 0으로 예측, 실제 값 역시 Positive 값 1\n",
    ">\n",
    "> TP : 예측값을 Positive 값 0으로 예측, 실제 값 역시 Positive 값 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix (array) :\n",
      " [[405   0]\n",
      " [ 45   0]]\n",
      "\n",
      "TN : 405,  FP : 0 \n",
      "FN : 45,  TP : 0\n"
     ]
    }
   ],
   "source": [
    "# 앞선 예제의 MyFakeClassifer의 예측 성능 지표를 오차 행렬로 표현하기\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, fakepred)\n",
    "print('confusion_matrix (array) :\\n', conf_mat)\n",
    "print()\n",
    "print('TN : {},  FP : {} \\nFN : {},  TP : {}'.format(conf_mat[0,0], conf_mat[0,1], conf_mat[1,0], conf_mat[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 정확도 (Accuracy) : (TN + TP) / (TN + FP + FN + TP)  --- 전체 데이터 수 중 예측 값이 실제 값과 동일한 건수 비율\n",
    "> \n",
    "> 정밀도 (Precision) : TP / (FP + TP)  --- 예측을 Positive로 한 대상 중 실제 값도 Positive로 일치한 데이터 비율\n",
    "> \n",
    "> 재현율 (Recall) : TP / (FN + TP)  --- 실제 값이 Positive인 대상 중에 예측 값도 Positive로 일치한 데이터 비율 (=민감도 Sensitivity 또는 TPR)\n",
    "\n",
    "- 재현율이 중요 지표인 경우 : 실제 Positive 양성 데이터를 Negative로 잘못 판단하면 업무상 큰 영향이 발생하는 경우 (ex : 암 판단, 보험 사기 적발 모델)\n",
    "- 정밀도가 중요 지표인 경우 : 실제 Negative인 데이터를 Positive로 잘못 판단하면 업무상 큰 영향이 발생하는 경우 (ex : 스팸 메일 분류)]\n",
    "- **두 지표 모두 TP를 높이는 데 초점을 맞추지만, 재현율은 FN을, 정밀도는 FP를 낮추는 데 초점을 맞춘다는 차이**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오차 행렬 및 정밀도, 재현율을 모두 구해서 예측 성능 평가하기\n",
    "- 정밀도 계산 : precision_score() API 사용\n",
    "- 재현율 계산 : recall_score() API 사용\n",
    "- get_clf_eval() : confusion matrix, accuracy, precision, recall 등의 평가를 한 번에 호출하는 함수 정의해 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 예제에 이어서 작성\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {0:.4f}, 정밀도 : {1:.4f}, 재현율 : {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7742, 재현율 : 0.7869\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 기반으로 타이타닉 생존자 예측 후, 평가 지표 호출\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터와 테스트 데이터로 분할\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                   test_size = 0.20, random_state = 11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도/재현율 트레이드오프\n",
    "- 분류의 결정 임곗값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다.\n",
    "- 이 때, 정밀도와 재현율은 상호 보완적 지표이기 때문에 어느 한쪽을 높이면 다른 수치는 떨어지기 쉬운데, 이를 Trade-off라고 한다.\n",
    "\n",
    "- predict_proba() : 학습이 완료된 사이킷런 Classifier 객체에서 호출이 가능하며, 테스트 피처 데이터 세트를 파라미터로 입력 시 테스트 피처 레코드의 개별 클래스 예측 확률을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba() 결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 :\n",
      " [[0.4623509  0.5376491 ]\n",
      " [0.87875882 0.12124118]\n",
      " [0.87717457 0.12282543]]\n",
      "두 개의 class 중 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.4623509  0.5376491  1.        ]\n",
      " [0.87875882 0.12124118 0.        ]\n",
      " [0.87717457 0.12282543 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba() 결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 :\\n', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결괏값 array를 병합(concatenate)해 예측 확률과 결괏값 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print('두 개의 class 중 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
